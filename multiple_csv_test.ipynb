{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "directory_path = \"C:\\gesture_recognition_by_image\\manus_files\"\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith(\".csv\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "combined_data = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for idx, file in enumerate(csv_files):\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\";\", usecols=list(range(0,2))+list(range(3,367)), decimal=',')\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    x.extend(df.values)\n",
    "    df['label'] = idx\n",
    "    y.extend(df[\"label\"].values)\n",
    "    combined_data = combined_data._append(df, ignore_index=True)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Assuming you have 4 output classes\n",
    "num_classes = 5\n",
    "y_encoded = to_categorical(y, num_classes=num_classes)\n",
    "y = y_encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1410, 366)\n",
      "(1410, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.000000e+00  0.000000e+00  0.000000e+00 ...  2.779287e+04\n",
      "   8.770906e+04  8.307434e+04]\n",
      " [ 1.000000e+00  1.600000e+01  0.000000e+00 ... -2.779287e+04\n",
      "  -8.770906e+04 -8.307434e+04]\n",
      " [ 2.000000e+00  3.200000e+01  0.000000e+00 ... -1.510448e+01\n",
      "  -6.179800e-02  6.179800e-02]\n",
      " ...\n",
      " [ 2.790000e+02  4.464000e+03  0.000000e+00 ...  9.644106e+01\n",
      "  -3.501890e-01 -4.978200e-02]\n",
      " [ 2.800000e+02  4.480000e+03  0.000000e+00 ...  8.736361e+01\n",
      "   1.055563e+02  9.473303e+01]\n",
      " [ 2.810000e+02  4.496000e+03  0.000000e+00 ... -2.471477e+02\n",
      "  -3.163684e+02 -2.841047e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_17 (Conv1D)          (None, 364, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPooli  (None, 182, 32)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 180, 64)           6208      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPooli  (None, 90, 64)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 88, 64)            12352     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 5632)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                360512    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379525 (1.45 MB)\n",
      "Trainable params: 379525 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(32, 3, activation='relu', input_shape=(366, 1)))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(64, 3, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(5))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\gesture_recognition_by_image\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\gesture_recognition_by_image\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "45/45 [==============================] - 2s 8ms/step - loss: 7.8841 - accuracy: 0.1943\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.7961 - accuracy: 0.2000\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 6.4472 - accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x196d16dab50>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',  # we used adam during machine learning course\n",
    "              loss='categorical_crossentropy',  # Multiclass classification loss\n",
    "              metrics=['accuracy'])  # Track accuracy during training\n",
    "\n",
    "model.fit(x,y,epochs=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
