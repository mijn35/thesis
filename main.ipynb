{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T15:28:04.213701400Z",
     "start_time": "2024-03-27T15:27:08.169752800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length is 315\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'csv_letters/*.csv'\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# Example class names\n",
    "class_names = [\"letterA\", \"letterB\", \"letterC\",\"letterD\",\"letterE\",\"letterF\",\"letterG\",\"letterH\",\"letterI\",\"letterK\",\"letterL\",\"letterM\",\"letterN\",\"letterO\",\"letterP\",\"letterQ\",\"letterR\",\"letterS\",\"letterT\",\"letterU\",\"letterV\",\"letterW\",\"letterX\",\"letterY\"]\n",
    "\n",
    "# Create a dictionary mapping class names to numerical labels\n",
    "class_to_label = {class_name: label for label, class_name in enumerate(class_names)}\n",
    "# Use glob to get all the csv files in the folder\n",
    "csv_files = glob.glob(folder_path)\n",
    "\n",
    "# Initialize an empty list to store the combined DataFrames\n",
    "combined_dataframes = []\n",
    "max_len = 0\n",
    "for i in range(1, len(csv_files), 2):\n",
    "    # Read the first file into a DataFrame\n",
    "    df1 = pd.read_csv(csv_files[i], header=0, delimiter=\";\", usecols=list(range(0,2))+list(range(3,367)), decimal=',')\n",
    "    if (len(df1)>max_len):\n",
    "        max_len = len(df1)\n",
    "print(f\"max length is {max_len}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T15:04:46.046875200Z",
     "start_time": "2024-03-19T15:04:42.101527200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n",
      "Shape of combined_df: (315, 732)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate over the files two by two\n",
    "for i in range(1, len(csv_files), 2):\n",
    "    # Read the first file into a DataFrame\n",
    "    df1 = pd.read_csv(csv_files[i], header=0, delimiter=\";\", usecols=list(range(0,2))+list(range(3,367)), decimal=',')\n",
    "    # Get the shape of df1\n",
    "    # print(f\"Shape of df1: {df1.shape}\")\n",
    "\n",
    "    #get the class and add it to y\n",
    "    name = os.path.splitext(csv_files[i])\n",
    "    classtype = name[0].split('\\\\')[1][:7] #this takes letterX from the title\n",
    "    numerical_label = class_to_label.get(classtype, -1)  # -1 if not found\n",
    "    if numerical_label != -1:\n",
    "        y.append(numerical_label)\n",
    "    else:\n",
    "        print(\"failed to add to y: \" + classtype)\n",
    "\n",
    "    # If there is a next file, read it and combine with the first\n",
    "    if i+1 < len(csv_files):\n",
    "        df2 = pd.read_csv(csv_files[i+1], header=0, delimiter=\";\", usecols=list(range(0,2))+list(range(3,367)), decimal=',')\n",
    "        df2 = df2.add_prefix('right_')\n",
    "    else:\n",
    "        # If there is no next file, create an empty DataFrame with the same columns as df1\n",
    "        df2 = pd.DataFrame(columns=df1.columns)\n",
    "\n",
    "    # Ensure that both DataFrames have the same number of rows by filling NaN values in df2\n",
    "    if len(df1) > len(df2):\n",
    "        df2 = df2.reindex(df1.index, fill_value=np.nan)\n",
    "    elif len(df2) > len(df1):\n",
    "        df1 = df1.reindex(df2.index, fill_value=np.nan)\n",
    "\n",
    "    # Concatenate the DataFrames\n",
    "    combined_df = pd.concat([df1, df2], axis=1)\n",
    "    combined_df = combined_df.reindex(range(max_len)).fillna(0)\n",
    "    # Print the shape of combined_df\n",
    "    print(f\"Shape of combined_df: {combined_df.shape}\")\n",
    "    combined_dataframes.append(combined_df)\n",
    "\n",
    "# Convert the list of DataFrames to a NumPy array\n",
    "x = np.array(combined_dataframes)\n",
    "x = np.asarray(x).astype('float32') # meant to fix an error when training the model\n",
    "y = np.array(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# print(x)\n",
    "# print(y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T15:04:52.946976100Z",
     "start_time": "2024-03-19T15:04:46.052831800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(64, 3, activation='relu', input_shape=(315,732)))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(24, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T15:04:53.041096800Z",
     "start_time": "2024-03-19T15:04:52.955488300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_18 (Conv1D)          (None, 313, 64)           140608    \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 156, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 154, 128)          24704     \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 77, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 75, 128)           49280     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 9600)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               1228928   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,453,336\n",
      "Trainable params: 1,453,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T15:04:53.102603900Z",
     "start_time": "2024-03-19T15:04:53.044095100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58797900\n",
      "255\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 1s 33ms/step - loss: 729.7145 - accuracy: 0.0539\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 114.8136 - accuracy: 0.1373\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 29.7235 - accuracy: 0.2941\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 11.9651 - accuracy: 0.4412\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 5.0993 - accuracy: 0.5686\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 2.2543 - accuracy: 0.7451\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.7723 - accuracy: 0.8235\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.4837 - accuracy: 0.8824\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3388 - accuracy: 0.9314\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2218 - accuracy: 0.9412\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.1962 - accuracy: 0.9461\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0671 - accuracy: 0.9657\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0222 - accuracy: 0.9951\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 9.5850e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 9.1119e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 8.5369e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 8.1100e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 7.7187e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 7.3682e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 7.1017e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 6.8161e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 6.5693e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 6.3272e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 6.0986e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 5.9122e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 5.7470e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 5.5444e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 5.3811e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 5.2292e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 5.0643e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 4.9022e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 4.7671e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 4.6216e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 4.5164e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 4.3921e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 4.2789e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 4.1776e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 4.0756e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 3.9601e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',  # we used adam during machine learning course\n",
    "              loss='sparse_categorical_crossentropy',  # Multiclass classification loss\n",
    "              metrics=['accuracy'])  # Track accuracy during training\n",
    "print(x.size)\n",
    "print(y.size)\n",
    "training_data = model.fit(x_train,y_train,epochs=50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T15:05:04.908032900Z",
     "start_time": "2024-03-19T15:04:53.075738800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 26.4745 - accuracy: 0.1569\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T15:05:05.266114900Z",
     "start_time": "2024-03-19T15:05:04.910035100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file 'letterC005_mijn35_L.csv' as it couldn't be read due to a ValueError.\n",
      "Skipping file 'letterD004_mijn35_L.csv' as it couldn't be read due to a ValueError.\n",
      "Skipping file 'letterS006_mijn35_L.csv' as it couldn't be read due to a ValueError.\n",
      "Skipping file 'letterT004_mijn35_L.csv' as it couldn't be read due to a ValueError.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to get the label based on the filename\n",
    "def get_label(filename):\n",
    "    letter = filename[6].lower()  # Get the letter from the filename and convert to lowercase\n",
    "    if letter == 'j':\n",
    "        return None  # Skip 'j'\n",
    "    else:\n",
    "        return ord(letter) - ord('a')  # Convert letter to corresponding integer label\n",
    "\n",
    "# Specify the folder path where your CSV files are located\n",
    "folder_path = 'csv_letters_filtered'\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each CSV file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        try:\n",
    "            # Read the first 50 rows from the CSV file\n",
    "            cols_to_use = list(range(3, 367))\n",
    "            df = pd.read_csv(file_path, header=0, nrows=50, delimiter=';', usecols=cols_to_use, decimal=',', dtype=float, skiprows=1)\n",
    "\n",
    "            # Check if the DataFrame has the right number of columns\n",
    "            if len(df.columns) != 364:  # Modify this number based on your expected number of columns\n",
    "                print(f\"Skipping file '{filename}' as it doesn't have the right number of columns.\")\n",
    "                continue\n",
    "\n",
    "            # Add a new column with the label\n",
    "            label = get_label(filename)\n",
    "            if label is not None:\n",
    "                df.insert(0, 'Label', label)\n",
    "\n",
    "            # Add a new column with the filename\n",
    "            #df['Original_Filename'] = filename\n",
    "\n",
    "            # Append the data to the combined DataFrame\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "        except ValueError:\n",
    "            print(f\"Skipping file '{filename}' as it couldn't be read due to a ValueError.\")\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_df.to_csv('combined_data.csv', index=False)\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T15:38:56.104864400Z",
     "start_time": "2024-03-27T15:38:55.472030400Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12178, 365)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('combined_data.csv', delimiter=\",\", decimal=\".\")\n",
    "print(df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 365)\n",
      "(9600, 365)\n",
      "Combined shape: (12000, 365)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = np.loadtxt('data_glove/data_martijn_zus.csv', delimiter=',', skiprows=1)\n",
    "df2 = np.loadtxt('data_glove/Data_joren.csv', delimiter=',')\n",
    "\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "\n",
    "if df1.shape[1] == df2.shape[1]:\n",
    "    combined_array = np.concatenate((df1, df2), axis=0)\n",
    "    print(\"Combined shape:\", combined_array.shape)\n",
    "else:\n",
    "    print(\"Number of columns in both arrays must be the same for concatenation.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 364)\n",
      "A\n",
      "(50, 364)\n",
      "A\n",
      "(50, 364)\n",
      "B\n",
      "(50, 364)\n",
      "B\n",
      "(50, 364)\n",
      "C\n",
      "(50, 364)\n",
      "C\n",
      "(50, 364)\n",
      "D\n",
      "(50, 364)\n",
      "D\n",
      "(50, 364)\n",
      "E\n",
      "(50, 364)\n",
      "E\n",
      "(50, 364)\n",
      "F\n",
      "(50, 364)\n",
      "F\n",
      "(50, 364)\n",
      "G\n",
      "(50, 364)\n",
      "G\n",
      "(50, 364)\n",
      "H\n",
      "(50, 364)\n",
      "H\n",
      "(50, 364)\n",
      "I\n",
      "(50, 364)\n",
      "I\n",
      "(50, 364)\n",
      "K\n",
      "(50, 364)\n",
      "K\n",
      "(50, 364)\n",
      "L\n",
      "(50, 364)\n",
      "L\n",
      "(50, 364)\n",
      "M\n",
      "(50, 364)\n",
      "M\n",
      "(50, 364)\n",
      "N\n",
      "(50, 364)\n",
      "N\n",
      "(50, 364)\n",
      "O\n",
      "(50, 364)\n",
      "O\n",
      "(50, 364)\n",
      "P\n",
      "(50, 364)\n",
      "P\n",
      "(50, 364)\n",
      "Q\n",
      "(50, 364)\n",
      "Q\n",
      "(50, 364)\n",
      "R\n",
      "(50, 364)\n",
      "R\n",
      "(50, 364)\n",
      "S\n",
      "(50, 364)\n",
      "S\n",
      "(50, 364)\n",
      "T\n",
      "(50, 364)\n",
      "T\n",
      "(50, 364)\n",
      "U\n",
      "(50, 364)\n",
      "U\n",
      "(50, 364)\n",
      "V\n",
      "(50, 364)\n",
      "V\n",
      "(50, 364)\n",
      "W\n",
      "(50, 364)\n",
      "W\n",
      "(50, 364)\n",
      "X\n",
      "(50, 364)\n",
      "X\n",
      "(50, 364)\n",
      "Y\n",
      "(50, 364)\n",
      "Y\n",
      "(2400, 365)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to convert letter to corresponding label\n",
    "def letter_to_label(letter):\n",
    "    if letter < 'J':\n",
    "        return ord(letter) - ord('A')\n",
    "    else:\n",
    "        return ord(letter) - ord('A') - 1\n",
    "\n",
    "# Path to the folder containing CSV files\n",
    "folder_path = 'csv_letters_martijn_moeder'\n",
    "\n",
    "# List to store dataframes for each file\n",
    "dfs = []\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read CSV file into a dataframe\n",
    "        df = pd.read_csv(os.path.join(folder_path, filename), delimiter=\";\", decimal=',', usecols=list(range(3, 367)))\n",
    "        # Take the first 50 samples\n",
    "        df = df.head(50)\n",
    "        print(df.shape)\n",
    "        # Extract the letter from the filename\n",
    "        letter = filename.split('_')[0][-4]\n",
    "        print(letter)\n",
    "        # Add a label column based on the letter\n",
    "        df['label'] = letter_to_label(letter)\n",
    "        df = df[['label'] + [col for col in df.columns if col != 'label']]\n",
    "        # Append dataframe to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "result_df = pd.concat(dfs)\n",
    "print(result_df.shape)\n",
    "\n",
    "# Write the result to a new CSV file\n",
    "result_df.to_csv('data_glove/data_martijn_moeder.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
