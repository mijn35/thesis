{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset_test = 'glove_data_test/glove_test_data.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier_glove.keras'\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier_glove.tflite'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "NUM_CLASSES = 24"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Directory containing CSV files\n",
    "directory = 'data_glove'\n",
    "\n",
    "# Initialize an empty list to store data from all files\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Load data from each file and append to the list\n",
    "        data_X.append(np.loadtxt(file_path, delimiter=',', dtype='float32', usecols=list(range(300, 325)) + list(range(4, 151))))\n",
    "        data_y.append(np.loadtxt(file_path, delimiter=',', dtype='float32', usecols=(0)))\n",
    "\n",
    "# Concatenate data from all files along the first axis\n",
    "X_dataset = np.concatenate(data_X, axis=0)\n",
    "y_dataset = np.concatenate(data_y, axis=0)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_dataset, y_dataset, train_size=0.70, random_state=RANDOM_SEED)\n",
    "X_test = np.loadtxt(dataset_test, delimiter=',', dtype='float32', usecols=list(range(300, 325)) + list(range(4, 151)))\n",
    "y_test = np.loadtxt(dataset_test, delimiter=',', dtype='int32', usecols=(0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train GQ shape:  (1397, 172)\n",
      "Y train GQ shape:  (1397,)\n",
      "X validation GQ shape:  (603, 172)\n",
      "Y validation GQ shape:  (603,)\n",
      "X test GQ shape:  (200, 172)\n",
      "Y test GQ shape:  (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train_GQ= []\n",
    "Y_train_GQ=[]\n",
    "for i, int_value in enumerate(y_train):\n",
    "    if int_value == 6 or int_value ==15:\n",
    "        X_train_GQ.append(X_train[i])\n",
    "        Y_train_GQ.append(y_train[i])\n",
    "X_train_GQ = np.array(X_train_GQ)\n",
    "Y_train_GQ = np.array(Y_train_GQ)\n",
    "\n",
    "X_test_GQ= []\n",
    "Y_test_GQ=[]\n",
    "for i, int_value in enumerate(y_test):\n",
    "    if int_value == 6 or int_value ==15:\n",
    "        X_test_GQ.append(X_test[i])\n",
    "        Y_test_GQ.append(y_test[i])\n",
    "X_test_GQ= np.array(X_test_GQ)\n",
    "Y_test_GQ = np.array(Y_test_GQ)\n",
    "\n",
    "\n",
    "X_validation_GQ=[]\n",
    "Y_validation_GQ=[]\n",
    "for i, int_value in enumerate(y_validation):\n",
    "    if int_value == 6 or int_value ==15:\n",
    "        X_validation_GQ.append(X_validation[i])\n",
    "        Y_validation_GQ.append(y_validation[i])\n",
    "X_validation_GQ = np.array(X_validation_GQ)\n",
    "Y_validation_GQ = np.array(Y_validation_GQ)\n",
    "\n",
    "print(\"X train GQ shape: \", X_train_GQ.shape)\n",
    "print(\"Y train GQ shape: \", Y_train_GQ.shape)\n",
    "print(\"X validation GQ shape: \", X_validation_GQ.shape)\n",
    "print(\"Y validation GQ shape: \", Y_validation_GQ.shape)\n",
    "print(\"X test GQ shape: \", X_test_GQ.shape)\n",
    "print(\"Y test GQ shape: \", Y_test_GQ.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Label mapping function\n",
    "def map_labels(labels):\n",
    "    return np.array([0 if label == 6 else 1 for label in labels])\n",
    "\n",
    "# Map labels in the train, validation, and test sets\n",
    "Y_train_GQ = map_labels(Y_train_GQ)\n",
    "Y_validation_GQ = map_labels(Y_validation_GQ)\n",
    "Y_test_GQ = map_labels(Y_test_GQ)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\thesis\\venv\\lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.5215 - loss: 7.6922\n",
      "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 35ms/step - accuracy: 0.5226 - loss: 7.5938 - val_accuracy: 0.6667 - val_loss: 0.7833\n",
      "Epoch 2/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.5317 - loss: 3.1643\n",
      "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.5339 - loss: 3.1309 - val_accuracy: 0.7264 - val_loss: 0.8401\n",
      "Epoch 3/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.5591 - loss: 2.1802\n",
      "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.5596 - loss: 2.1625 - val_accuracy: 0.8192 - val_loss: 0.7409\n",
      "Epoch 4/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.5588 - loss: 1.3583\n",
      "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.5602 - loss: 1.3523 - val_accuracy: 0.8292 - val_loss: 0.5955\n",
      "Epoch 5/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6627 - loss: 1.0863\n",
      "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6613 - loss: 1.0870 - val_accuracy: 0.7081 - val_loss: 0.7019\n",
      "Epoch 6/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6481 - loss: 1.0853\n",
      "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.6481 - loss: 1.1138 - val_accuracy: 0.8109 - val_loss: 0.6629\n",
      "Epoch 7/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6915 - loss: 0.9083\n",
      "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6916 - loss: 0.9017 - val_accuracy: 0.8060 - val_loss: 0.7076\n",
      "Epoch 8/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6865 - loss: 1.3718\n",
      "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.6873 - loss: 1.3610 - val_accuracy: 0.8259 - val_loss: 0.8010\n",
      "Epoch 9/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.6995 - loss: 0.9815\n",
      "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6994 - loss: 0.9713 - val_accuracy: 0.7430 - val_loss: 0.7333\n",
      "Epoch 10/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7258 - loss: 0.6173\n",
      "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7267 - loss: 0.6207 - val_accuracy: 0.8159 - val_loss: 0.5635\n",
      "Epoch 11/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7140 - loss: 0.8107\n",
      "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7164 - loss: 0.8157 - val_accuracy: 0.8391 - val_loss: 0.4125\n",
      "Epoch 12/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7738 - loss: 0.4843\n",
      "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7745 - loss: 0.4846 - val_accuracy: 0.8823 - val_loss: 0.3977\n",
      "Epoch 13/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7753 - loss: 1.3780\n",
      "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7758 - loss: 1.3585 - val_accuracy: 0.8242 - val_loss: 0.4979\n",
      "Epoch 14/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7892 - loss: 0.6996\n",
      "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7891 - loss: 0.7028 - val_accuracy: 0.8126 - val_loss: 0.4682\n",
      "Epoch 15/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7965 - loss: 0.3936\n",
      "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.7969 - loss: 0.3938 - val_accuracy: 0.8574 - val_loss: 0.3758\n",
      "Epoch 16/1000\n",
      "\u001B[1m 9/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8191 - loss: 0.7645\n",
      "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8211 - loss: 0.6922 - val_accuracy: 0.8391 - val_loss: 0.3664\n",
      "Epoch 17/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8419 - loss: 0.6658\n",
      "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8412 - loss: 0.6631 - val_accuracy: 0.8706 - val_loss: 0.4046\n",
      "Epoch 18/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8056 - loss: 1.0004\n",
      "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8069 - loss: 0.9777 - val_accuracy: 0.8574 - val_loss: 0.3185\n",
      "Epoch 19/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8302 - loss: 0.5043\n",
      "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8313 - loss: 0.4967 - val_accuracy: 0.9436 - val_loss: 0.3005\n",
      "Epoch 20/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8262 - loss: 0.4901\n",
      "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8263 - loss: 0.4845 - val_accuracy: 0.8823 - val_loss: 0.2653\n",
      "Epoch 21/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8525 - loss: 0.6494\n",
      "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8519 - loss: 0.6533 - val_accuracy: 0.8723 - val_loss: 0.2511\n",
      "Epoch 22/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8441 - loss: 0.4547\n",
      "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8448 - loss: 0.4620 - val_accuracy: 0.9270 - val_loss: 0.2385\n",
      "Epoch 23/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8453 - loss: 0.7879\n",
      "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8461 - loss: 0.7802 - val_accuracy: 0.9337 - val_loss: 0.2940\n",
      "Epoch 24/1000\n",
      "\u001B[1m10/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.8592 - loss: 0.3731\n",
      "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8574 - loss: 0.3913 - val_accuracy: 0.9005 - val_loss: 0.2117\n",
      "Epoch 25/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8634 - loss: 0.4216\n",
      "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8635 - loss: 0.4190 - val_accuracy: 0.9022 - val_loss: 0.2129\n",
      "Epoch 26/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8777 - loss: 0.4081\n",
      "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8774 - loss: 0.4090 - val_accuracy: 0.9619 - val_loss: 0.2268\n",
      "Epoch 27/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8723 - loss: 0.5496\n",
      "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8728 - loss: 0.5373 - val_accuracy: 0.9403 - val_loss: 0.2131\n",
      "Epoch 28/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8674 - loss: 0.3287\n",
      "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8684 - loss: 0.3301 - val_accuracy: 0.9403 - val_loss: 0.2103\n",
      "Epoch 29/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8758 - loss: 0.4239\n",
      "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8758 - loss: 0.4305 - val_accuracy: 0.9303 - val_loss: 0.1978\n",
      "Epoch 30/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8924 - loss: 0.2306\n",
      "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8923 - loss: 0.2316 - val_accuracy: 0.9337 - val_loss: 0.2272\n",
      "Epoch 31/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9004 - loss: 0.2540\n",
      "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9000 - loss: 0.2557 - val_accuracy: 0.9685 - val_loss: 0.2037\n",
      "Epoch 32/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9027 - loss: 0.2134\n",
      "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9027 - loss: 0.2201 - val_accuracy: 0.9519 - val_loss: 0.1775\n",
      "Epoch 33/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8929 - loss: 0.3276\n",
      "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8924 - loss: 0.3278 - val_accuracy: 0.9420 - val_loss: 0.1686\n",
      "Epoch 34/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9058 - loss: 0.2205\n",
      "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9059 - loss: 0.2237 - val_accuracy: 0.9320 - val_loss: 0.1698\n",
      "Epoch 35/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9069 - loss: 0.1955\n",
      "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9072 - loss: 0.1967 - val_accuracy: 0.9270 - val_loss: 0.1436\n",
      "Epoch 36/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8873 - loss: 0.2891\n",
      "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8873 - loss: 0.2906 - val_accuracy: 0.9386 - val_loss: 0.1637\n",
      "Epoch 37/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9072 - loss: 0.6809\n",
      "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9077 - loss: 0.6550 - val_accuracy: 0.9585 - val_loss: 0.1277\n",
      "Epoch 38/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8952 - loss: 0.2598\n",
      "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8961 - loss: 0.2592 - val_accuracy: 0.9320 - val_loss: 0.1817\n",
      "Epoch 39/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9043 - loss: 0.3551\n",
      "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9043 - loss: 0.3510 - val_accuracy: 0.9784 - val_loss: 0.1980\n",
      "Epoch 40/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9152 - loss: 0.2485\n",
      "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9153 - loss: 0.2475 - val_accuracy: 0.9519 - val_loss: 0.1635\n",
      "Epoch 41/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9266 - loss: 0.2034\n",
      "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9258 - loss: 0.2058 - val_accuracy: 0.9917 - val_loss: 0.1089\n",
      "Epoch 42/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8964 - loss: 0.2457\n",
      "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8973 - loss: 0.2513 - val_accuracy: 0.9619 - val_loss: 0.1152\n",
      "Epoch 43/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9317 - loss: 0.2894\n",
      "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9309 - loss: 0.2994 - val_accuracy: 0.9867 - val_loss: 0.1480\n",
      "Epoch 44/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9151 - loss: 0.2855\n",
      "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9161 - loss: 0.2813 - val_accuracy: 0.9768 - val_loss: 0.1266\n",
      "Epoch 45/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9073 - loss: 0.2436\n",
      "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9081 - loss: 0.2409 - val_accuracy: 0.9552 - val_loss: 0.1091\n",
      "Epoch 46/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9203 - loss: 0.1630\n",
      "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9204 - loss: 0.1635 - val_accuracy: 0.9917 - val_loss: 0.0990\n",
      "Epoch 47/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9188 - loss: 0.2787\n",
      "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9192 - loss: 0.2773 - val_accuracy: 0.9818 - val_loss: 0.1229\n",
      "Epoch 48/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9293 - loss: 0.1658\n",
      "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9291 - loss: 0.1665 - val_accuracy: 0.9851 - val_loss: 0.1103\n",
      "Epoch 49/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9430 - loss: 0.1486\n",
      "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9425 - loss: 0.1490 - val_accuracy: 0.9818 - val_loss: 0.1025\n",
      "Epoch 50/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9356 - loss: 0.1805\n",
      "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9352 - loss: 0.1835 - val_accuracy: 0.9552 - val_loss: 0.1027\n",
      "Epoch 51/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9272 - loss: 0.1788\n",
      "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9275 - loss: 0.1837 - val_accuracy: 0.9900 - val_loss: 0.0928\n",
      "Epoch 52/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9423 - loss: 0.1379\n",
      "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9422 - loss: 0.1378 - val_accuracy: 0.9867 - val_loss: 0.0931\n",
      "Epoch 53/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9390 - loss: 0.1568\n",
      "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9391 - loss: 0.1591 - val_accuracy: 0.9818 - val_loss: 0.0895\n",
      "Epoch 54/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9387 - loss: 0.1555\n",
      "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9390 - loss: 0.1552 - val_accuracy: 0.9867 - val_loss: 0.0840\n",
      "Epoch 55/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9305 - loss: 0.2960\n",
      "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9310 - loss: 0.2897 - val_accuracy: 0.9900 - val_loss: 0.0837\n",
      "Epoch 56/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9446 - loss: 0.3598\n",
      "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9449 - loss: 0.3489 - val_accuracy: 0.9768 - val_loss: 0.0735\n",
      "Epoch 57/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9292 - loss: 0.1950\n",
      "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9298 - loss: 0.1931 - val_accuracy: 0.9900 - val_loss: 0.1226\n",
      "Epoch 58/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9474 - loss: 0.1369\n",
      "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9475 - loss: 0.1363 - val_accuracy: 0.9818 - val_loss: 0.1328\n",
      "Epoch 59/1000\n",
      "\u001B[1m 9/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9433 - loss: 0.1512\n",
      "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9445 - loss: 0.1645 - val_accuracy: 0.9900 - val_loss: 0.0948\n",
      "Epoch 60/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9502 - loss: 0.2384\n",
      "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9503 - loss: 0.2332 - val_accuracy: 0.9900 - val_loss: 0.0695\n",
      "Epoch 61/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9539 - loss: 0.1222\n",
      "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9538 - loss: 0.1219 - val_accuracy: 0.9917 - val_loss: 0.0762\n",
      "Epoch 62/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9650 - loss: 0.0968\n",
      "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9644 - loss: 0.0978 - val_accuracy: 0.9818 - val_loss: 0.0852\n",
      "Epoch 63/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9579 - loss: 0.2019\n",
      "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9577 - loss: 0.1990 - val_accuracy: 0.9900 - val_loss: 0.0521\n",
      "Epoch 64/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9662 - loss: 0.0983\n",
      "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9658 - loss: 0.0993 - val_accuracy: 0.9917 - val_loss: 0.0504\n",
      "Epoch 65/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9695 - loss: 0.1001\n",
      "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9696 - loss: 0.0998 - val_accuracy: 0.9900 - val_loss: 0.0471\n",
      "Epoch 66/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9664 - loss: 0.0931\n",
      "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9660 - loss: 0.0933 - val_accuracy: 0.9917 - val_loss: 0.0466\n",
      "Epoch 67/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9508 - loss: 0.1172\n",
      "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9510 - loss: 0.1167 - val_accuracy: 0.9934 - val_loss: 0.0391\n",
      "Epoch 68/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9579 - loss: 0.1179\n",
      "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9579 - loss: 0.1209 - val_accuracy: 0.9917 - val_loss: 0.0315\n",
      "Epoch 69/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9729 - loss: 0.1194\n",
      "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9725 - loss: 0.1189 - val_accuracy: 0.9867 - val_loss: 0.0456\n",
      "Epoch 70/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9512 - loss: 0.1207\n",
      "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9517 - loss: 0.1206 - val_accuracy: 0.9934 - val_loss: 0.0325\n",
      "Epoch 71/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9686 - loss: 0.0811\n",
      "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9680 - loss: 0.0825 - val_accuracy: 0.9950 - val_loss: 0.0322\n",
      "Epoch 72/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9664 - loss: 0.1466\n",
      "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9662 - loss: 0.1475 - val_accuracy: 0.9917 - val_loss: 0.0312\n",
      "Epoch 73/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9734 - loss: 0.0740\n",
      "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9731 - loss: 0.0773 - val_accuracy: 0.9917 - val_loss: 0.0252\n",
      "Epoch 74/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9698 - loss: 0.0803\n",
      "Epoch 74: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9694 - loss: 0.0813 - val_accuracy: 0.9934 - val_loss: 0.0301\n",
      "Epoch 75/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9708 - loss: 0.0861\n",
      "Epoch 75: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9707 - loss: 0.0863 - val_accuracy: 0.9867 - val_loss: 0.0332\n",
      "Epoch 76/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9639 - loss: 0.0891\n",
      "Epoch 76: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9638 - loss: 0.0892 - val_accuracy: 0.9934 - val_loss: 0.0301\n",
      "Epoch 77/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9687 - loss: 0.0940\n",
      "Epoch 77: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9688 - loss: 0.0942 - val_accuracy: 0.9900 - val_loss: 0.0262\n",
      "Epoch 78/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9567 - loss: 0.1297\n",
      "Epoch 78: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9567 - loss: 0.1321 - val_accuracy: 0.9900 - val_loss: 0.0513\n",
      "Epoch 79/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9543 - loss: 0.1386\n",
      "Epoch 79: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9542 - loss: 0.1385 - val_accuracy: 0.9917 - val_loss: 0.0518\n",
      "Epoch 80/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9575 - loss: 0.1086\n",
      "Epoch 80: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9572 - loss: 0.1086 - val_accuracy: 0.9917 - val_loss: 0.0534\n",
      "Epoch 81/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9522 - loss: 0.1622\n",
      "Epoch 81: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9527 - loss: 0.1588 - val_accuracy: 0.9917 - val_loss: 0.0417\n",
      "Epoch 82/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9718 - loss: 0.1014\n",
      "Epoch 82: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9717 - loss: 0.1008 - val_accuracy: 0.9950 - val_loss: 0.0182\n",
      "Epoch 83/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9644 - loss: 0.0954\n",
      "Epoch 83: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9648 - loss: 0.0942 - val_accuracy: 0.9950 - val_loss: 0.0202\n",
      "Epoch 84/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9724 - loss: 0.0827\n",
      "Epoch 84: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9723 - loss: 0.0822 - val_accuracy: 0.9967 - val_loss: 0.0151\n",
      "Epoch 85/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9770 - loss: 0.0704\n",
      "Epoch 85: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9768 - loss: 0.0709 - val_accuracy: 0.9983 - val_loss: 0.0135\n",
      "Epoch 86/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9753 - loss: 0.1336\n",
      "Epoch 86: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9747 - loss: 0.1344 - val_accuracy: 0.9818 - val_loss: 0.0351\n",
      "Epoch 87/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9693 - loss: 0.0882\n",
      "Epoch 87: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9695 - loss: 0.0876 - val_accuracy: 0.9950 - val_loss: 0.0220\n",
      "Epoch 88/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9626 - loss: 0.2375\n",
      "Epoch 88: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9628 - loss: 0.2319 - val_accuracy: 0.9934 - val_loss: 0.0447\n",
      "Epoch 89/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9756 - loss: 0.0828\n",
      "Epoch 89: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9756 - loss: 0.0846 - val_accuracy: 0.9934 - val_loss: 0.0398\n",
      "Epoch 90/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9784 - loss: 0.1007\n",
      "Epoch 90: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9780 - loss: 0.1066 - val_accuracy: 0.9967 - val_loss: 0.0535\n",
      "Epoch 91/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9755 - loss: 0.0868\n",
      "Epoch 91: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9752 - loss: 0.0907 - val_accuracy: 0.9917 - val_loss: 0.0271\n",
      "Epoch 92/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9590 - loss: 0.1083\n",
      "Epoch 92: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9596 - loss: 0.1082 - val_accuracy: 0.9900 - val_loss: 0.0279\n",
      "Epoch 93/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9597 - loss: 0.2027\n",
      "Epoch 93: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9603 - loss: 0.1959 - val_accuracy: 0.9950 - val_loss: 0.0324\n",
      "Epoch 94/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9834 - loss: 0.0998\n",
      "Epoch 94: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9826 - loss: 0.1013 - val_accuracy: 0.9983 - val_loss: 0.0146\n",
      "Epoch 95/1000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9648 - loss: 0.0816\n",
      "Epoch 95: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9653 - loss: 0.0813 - val_accuracy: 0.9983 - val_loss: 0.0180\n",
      "Epoch 95: early stopping\n"
     ]
    }
   ],
   "source": [
    "GQ_CLASSES = 2\n",
    "GQmodel = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((172, 1), input_shape=(172,)),\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=10),\n",
    "    tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.8),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(GQ_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "GQmodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1)\n",
    "\n",
    "history = GQmodel.fit(\n",
    "    X_train_GQ,\n",
    "    Y_train_GQ,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_validation_GQ, Y_validation_GQ),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.0376 - loss: 4.0861\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = GQmodel.evaluate(X_test_GQ, Y_test_GQ, batch_size = 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 700x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2400, 200]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 24\u001B[0m\n\u001B[0;32m     21\u001B[0m Y_pred_GQ \u001B[38;5;241m=\u001B[39m GQmodel\u001B[38;5;241m.\u001B[39mpredict(X_test_GQ)\n\u001B[0;32m     22\u001B[0m Y_pred_GQ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(Y_pred_GQ, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 24\u001B[0m \u001B[43mprint_confusion_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mY_test_GQ\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_pred_GQ\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[33], line 19\u001B[0m, in \u001B[0;36mprint_confusion_matrix\u001B[1;34m(y_true, y_pred, report)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m report:\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClassification Report\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mclassification_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mC:\\thesis\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mC:\\thesis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2604\u001B[0m, in \u001B[0;36mclassification_report\u001B[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001B[0m\n\u001B[0;32m   2469\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m   2470\u001B[0m     {\n\u001B[0;32m   2471\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2495\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2496\u001B[0m ):\n\u001B[0;32m   2497\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001B[39;00m\n\u001B[0;32m   2498\u001B[0m \n\u001B[0;32m   2499\u001B[0m \u001B[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2601\u001B[0m \u001B[38;5;124;03m    <BLANKLINE>\u001B[39;00m\n\u001B[0;32m   2602\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2604\u001B[0m     y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2606\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2607\u001B[0m         labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\n",
      "File \u001B[1;32mC:\\thesis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_targets\u001B[39m(y_true, y_pred):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \n\u001B[0;32m     61\u001B[0m \u001B[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;124;03m    y_pred : array or indicator matrix\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m     \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m     type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     87\u001B[0m     type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\thesis\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:457\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    455\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 457\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    458\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    459\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    460\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [2400, 200]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "\n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred_GQ = GQmodel.predict(X_test_GQ)\n",
    "Y_pred_GQ = np.argmax(Y_pred_GQ, axis=1)\n",
    "\n",
    "print_confusion_matrix(Y_test_GQ, Y_pred_GQ)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
