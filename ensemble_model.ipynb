{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:51:10.860933100Z",
     "start_time": "2024-04-20T15:51:10.840486300Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "dataset_test = 'glove_data_test/glove_test_data.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier_glove.keras'\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier_glove.tflite'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:51:11.070694200Z",
     "start_time": "2024-04-20T15:51:11.064406900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "NUM_CLASSES = 24"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:51:11.376523900Z",
     "start_time": "2024-04-20T15:51:11.372015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Directory containing CSV files\n",
    "directory = 'data_glove'\n",
    "\n",
    "# Initialize an empty list to store data from all files\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Load data from each file and append to the list\n",
    "        data_X.append(np.loadtxt(file_path, delimiter=',', dtype='float32', usecols=list(range(300, 325)) + list(range(4, 151))))\n",
    "        data_y.append(np.loadtxt(file_path, delimiter=',', dtype='float32', usecols=(0)))\n",
    "\n",
    "# Concatenate data from all files along the first axis\n",
    "X_dataset = np.concatenate(data_X, axis=0)\n",
    "y_dataset = np.concatenate(data_y, axis=0)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_dataset, y_dataset, train_size=0.70, random_state=RANDOM_SEED)\n",
    "X_test = np.loadtxt(dataset_test, delimiter=',', dtype='float32', usecols=list(range(300, 325)) + list(range(4, 151)))\n",
    "y_test = np.loadtxt(dataset_test, delimiter=',', dtype='int32', usecols=(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:51:13.119173900Z",
     "start_time": "2024-04-20T15:51:11.673762500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train GQ shape:  (1397, 172)\n",
      "Y train GQ shape:  (1397,)\n",
      "X validation GQ shape:  (603, 172)\n",
      "Y validation GQ shape:  (603,)\n",
      "X test GQ shape:  (200, 172)\n",
      "Y test GQ shape:  (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train_GQ= []\n",
    "Y_train_GQ=[]\n",
    "for i, int_value in enumerate(y_train):\n",
    "    if int_value == 6 or int_value ==15:\n",
    "        X_train_GQ.append(X_train[i])\n",
    "        Y_train_GQ.append(y_train[i])\n",
    "X_train_GQ = np.array(X_train_GQ)\n",
    "Y_train_GQ = np.array(Y_train_GQ)\n",
    "\n",
    "X_test_GQ= []\n",
    "Y_test_GQ=[]\n",
    "for i, int_value in enumerate(y_test):\n",
    "    if int_value == 6 or int_value ==15:\n",
    "        X_test_GQ.append(X_test[i])\n",
    "        Y_test_GQ.append(y_test[i])\n",
    "X_test_GQ= np.array(X_test_GQ)\n",
    "Y_test_GQ = np.array(Y_test_GQ)\n",
    "\n",
    "\n",
    "X_validation_GQ=[]\n",
    "Y_validation_GQ=[]\n",
    "for i, int_value in enumerate(y_validation):\n",
    "    if int_value == 6 or int_value ==15:\n",
    "        X_validation_GQ.append(X_validation[i])\n",
    "        Y_validation_GQ.append(y_validation[i])\n",
    "X_validation_GQ = np.array(X_validation_GQ)\n",
    "Y_validation_GQ = np.array(Y_validation_GQ)\n",
    "\n",
    "print(\"X train GQ shape: \", X_train_GQ.shape)\n",
    "print(\"Y train GQ shape: \", Y_train_GQ.shape)\n",
    "print(\"X validation GQ shape: \", X_validation_GQ.shape)\n",
    "print(\"Y validation GQ shape: \", Y_validation_GQ.shape)\n",
    "print(\"X test GQ shape: \", X_test_GQ.shape)\n",
    "print(\"Y test GQ shape: \", Y_test_GQ.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:51:13.195454300Z",
     "start_time": "2024-04-20T15:51:13.121173100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Label mapping function\n",
    "def map_labels(labels):\n",
    "    return np.array([0 if label == 6 else 1 for label in labels])\n",
    "\n",
    "# Map labels in the train, validation, and test sets\n",
    "Y_train_GQ = map_labels(Y_train_GQ)\n",
    "Y_validation_GQ = map_labels(Y_validation_GQ)\n",
    "Y_test_GQ = map_labels(Y_test_GQ)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:51:13.206676300Z",
     "start_time": "2024-04-20T15:51:13.204991500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zomaa\\IdeaProjects\\master\\venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m23s\u001B[0m 2s/step - accuracy: 0.5078 - loss: 10.0958\n",
      "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.5157 - loss: 8.0938 - val_accuracy: 0.6700 - val_loss: 1.1013\n",
      "Epoch 2/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.5547 - loss: 2.9267\n",
      "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.5658 - loss: 2.7260 - val_accuracy: 0.7313 - val_loss: 0.7927\n",
      "Epoch 3/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6406 - loss: 3.4025\n",
      "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.6045 - loss: 2.0299 - val_accuracy: 0.7612 - val_loss: 0.6844\n",
      "Epoch 4/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.6328 - loss: 0.7920\n",
      "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.6338 - loss: 1.1002 - val_accuracy: 0.8043 - val_loss: 0.7148\n",
      "Epoch 5/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6250 - loss: 2.1524\n",
      "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.6486 - loss: 1.1364 - val_accuracy: 0.8176 - val_loss: 0.6774\n",
      "Epoch 6/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.7031 - loss: 1.1981\n",
      "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.6943 - loss: 1.1340 - val_accuracy: 0.8491 - val_loss: 0.7268\n",
      "Epoch 7/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.7188 - loss: 0.5364\n",
      "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7098 - loss: 0.7272 - val_accuracy: 0.8441 - val_loss: 0.6619\n",
      "Epoch 8/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6641 - loss: 0.5547\n",
      "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.6914 - loss: 0.6168 - val_accuracy: 0.8109 - val_loss: 0.6100\n",
      "Epoch 9/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.7344 - loss: 0.4460\n",
      "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7227 - loss: 0.5416 - val_accuracy: 0.8441 - val_loss: 0.4678\n",
      "Epoch 10/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.7344 - loss: 0.5721\n",
      "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7307 - loss: 0.6292 - val_accuracy: 0.8358 - val_loss: 0.4385\n",
      "Epoch 11/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8516 - loss: 1.2823\n",
      "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7939 - loss: 0.6870 - val_accuracy: 0.8159 - val_loss: 0.5564\n",
      "Epoch 12/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8125 - loss: 0.3499\n",
      "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7675 - loss: 1.1143 - val_accuracy: 0.8789 - val_loss: 0.5072\n",
      "Epoch 13/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7422 - loss: 0.4958\n",
      "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7719 - loss: 0.5022 - val_accuracy: 0.8723 - val_loss: 0.4061\n",
      "Epoch 14/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.7109 - loss: 0.4678\n",
      "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7667 - loss: 0.5428 - val_accuracy: 0.9055 - val_loss: 0.3797\n",
      "Epoch 15/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.7656 - loss: 0.5567\n",
      "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7947 - loss: 0.4982 - val_accuracy: 0.8557 - val_loss: 0.3281\n",
      "Epoch 16/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.7656 - loss: 0.4350\n",
      "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7804 - loss: 0.4510 - val_accuracy: 0.9005 - val_loss: 0.2995\n",
      "Epoch 17/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.7578 - loss: 0.4301\n",
      "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7850 - loss: 0.7678 - val_accuracy: 0.9005 - val_loss: 0.2964\n",
      "Epoch 18/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8125 - loss: 0.3397\n",
      "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8173 - loss: 0.5173 - val_accuracy: 0.9303 - val_loss: 0.2856\n",
      "Epoch 19/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.8047 - loss: 0.3640\n",
      "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8346 - loss: 0.3362 - val_accuracy: 0.9055 - val_loss: 0.2872\n",
      "Epoch 20/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8047 - loss: 0.3662\n",
      "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8375 - loss: 0.4386 - val_accuracy: 0.8939 - val_loss: 0.2825\n",
      "Epoch 21/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.7969 - loss: 0.3922\n",
      "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8335 - loss: 0.3712 - val_accuracy: 0.9138 - val_loss: 0.2486\n",
      "Epoch 22/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8906 - loss: 0.2653\n",
      "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8524 - loss: 0.3495 - val_accuracy: 0.9138 - val_loss: 0.2405\n",
      "Epoch 23/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8828 - loss: 0.2696\n",
      "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8616 - loss: 0.3303 - val_accuracy: 0.9055 - val_loss: 0.2180\n",
      "Epoch 24/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8281 - loss: 0.4607\n",
      "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8490 - loss: 0.4352 - val_accuracy: 0.9420 - val_loss: 0.2019\n",
      "Epoch 25/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8828 - loss: 0.2506\n",
      "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8767 - loss: 0.3073 - val_accuracy: 0.9270 - val_loss: 0.2125\n",
      "Epoch 26/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8750 - loss: 0.2877\n",
      "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8792 - loss: 0.3178 - val_accuracy: 0.9386 - val_loss: 0.2279\n",
      "Epoch 27/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8984 - loss: 0.2672\n",
      "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8857 - loss: 0.2709 - val_accuracy: 0.9154 - val_loss: 0.1807\n",
      "Epoch 28/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8828 - loss: 0.2503\n",
      "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8860 - loss: 0.3303 - val_accuracy: 0.9337 - val_loss: 0.1827\n",
      "Epoch 29/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9141 - loss: 0.2308\n",
      "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8807 - loss: 0.2921 - val_accuracy: 0.9287 - val_loss: 0.1817\n",
      "Epoch 30/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8516 - loss: 0.3130\n",
      "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8690 - loss: 0.3040 - val_accuracy: 0.9403 - val_loss: 0.1928\n",
      "Epoch 31/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.9297 - loss: 0.1611\n",
      "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8938 - loss: 0.2974 - val_accuracy: 0.9237 - val_loss: 0.2256\n",
      "Epoch 32/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9375 - loss: 0.1949\n",
      "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8911 - loss: 0.2947 - val_accuracy: 0.9204 - val_loss: 0.1907\n",
      "Epoch 33/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8750 - loss: 0.2527\n",
      "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8745 - loss: 0.2713 - val_accuracy: 0.9254 - val_loss: 0.1888\n",
      "Epoch 34/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8906 - loss: 0.3487\n",
      "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8781 - loss: 0.3348 - val_accuracy: 0.9585 - val_loss: 0.1707\n",
      "Epoch 35/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.9297 - loss: 0.2054\n",
      "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8966 - loss: 0.2540 - val_accuracy: 0.9420 - val_loss: 0.1806\n",
      "Epoch 36/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9297 - loss: 0.2349\n",
      "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9088 - loss: 0.2163 - val_accuracy: 0.9436 - val_loss: 0.1839\n",
      "Epoch 37/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9141 - loss: 0.2093\n",
      "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9011 - loss: 0.2262 - val_accuracy: 0.9751 - val_loss: 0.1768\n",
      "Epoch 38/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8750 - loss: 0.2548\n",
      "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8922 - loss: 0.3001 - val_accuracy: 0.9701 - val_loss: 0.1522\n",
      "Epoch 39/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9062 - loss: 0.2566\n",
      "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9034 - loss: 0.2254 - val_accuracy: 0.9254 - val_loss: 0.1734\n",
      "Epoch 40/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9219 - loss: 0.6903\n",
      "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9066 - loss: 0.3908 - val_accuracy: 0.9436 - val_loss: 0.1346\n",
      "Epoch 41/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9062 - loss: 0.2603\n",
      "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9010 - loss: 0.2748 - val_accuracy: 0.9337 - val_loss: 0.1364\n",
      "Epoch 42/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9062 - loss: 0.2173\n",
      "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9113 - loss: 0.2424 - val_accuracy: 0.9403 - val_loss: 0.1685\n",
      "Epoch 43/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9375 - loss: 0.1982\n",
      "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9150 - loss: 0.2564 - val_accuracy: 0.9403 - val_loss: 0.1887\n",
      "Epoch 44/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9141 - loss: 0.1974\n",
      "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9125 - loss: 0.2030 - val_accuracy: 0.9386 - val_loss: 0.1718\n",
      "Epoch 45/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9375 - loss: 0.1655\n",
      "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8979 - loss: 0.2341 - val_accuracy: 0.9386 - val_loss: 0.1418\n",
      "Epoch 46/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9062 - loss: 0.2730\n",
      "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9236 - loss: 0.2158 - val_accuracy: 0.9900 - val_loss: 0.1256\n",
      "Epoch 47/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8984 - loss: 0.1856\n",
      "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9032 - loss: 0.2196 - val_accuracy: 0.9436 - val_loss: 0.1113\n",
      "Epoch 48/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9219 - loss: 0.1699\n",
      "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9174 - loss: 0.1827 - val_accuracy: 0.9386 - val_loss: 0.1137\n",
      "Epoch 49/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9297 - loss: 0.1773\n",
      "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9194 - loss: 0.1818 - val_accuracy: 0.9420 - val_loss: 0.1147\n",
      "Epoch 50/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9531 - loss: 0.1643\n",
      "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9315 - loss: 0.1811 - val_accuracy: 0.9652 - val_loss: 0.1066\n",
      "Epoch 51/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9375 - loss: 0.1913\n",
      "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9188 - loss: 0.1874 - val_accuracy: 0.9569 - val_loss: 0.1396\n",
      "Epoch 52/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.9141 - loss: 0.5465\n",
      "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9248 - loss: 0.2850 - val_accuracy: 0.9884 - val_loss: 0.1271\n",
      "Epoch 53/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1s\u001B[0m 101ms/step - accuracy: 0.9219 - loss: 0.1502\n",
      "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9206 - loss: 0.2419 - val_accuracy: 0.9585 - val_loss: 0.1235\n",
      "Epoch 54/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9531 - loss: 0.1476\n",
      "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9372 - loss: 0.2072 - val_accuracy: 0.9585 - val_loss: 0.1300\n",
      "Epoch 55/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1s\u001B[0m 104ms/step - accuracy: 0.9219 - loss: 0.1696\n",
      "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9313 - loss: 0.1967 - val_accuracy: 0.9585 - val_loss: 0.1175\n",
      "Epoch 56/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9375 - loss: 0.1449\n",
      "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9315 - loss: 0.1674 - val_accuracy: 0.9585 - val_loss: 0.1075\n",
      "Epoch 57/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9297 - loss: 0.1543\n",
      "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9237 - loss: 0.1785 - val_accuracy: 0.9602 - val_loss: 0.1004\n",
      "Epoch 58/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8828 - loss: 0.2257\n",
      "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9239 - loss: 0.2053 - val_accuracy: 0.9818 - val_loss: 0.0895\n",
      "Epoch 59/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9609 - loss: 0.1092\n",
      "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9375 - loss: 0.1714 - val_accuracy: 0.9834 - val_loss: 0.0944\n",
      "Epoch 60/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9531 - loss: 0.1427\n",
      "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9495 - loss: 0.1530 - val_accuracy: 0.9867 - val_loss: 0.1069\n",
      "Epoch 61/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.9453 - loss: 0.1662\n",
      "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9428 - loss: 0.1664 - val_accuracy: 0.9602 - val_loss: 0.0921\n",
      "Epoch 62/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9453 - loss: 0.1416\n",
      "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9342 - loss: 0.1608 - val_accuracy: 0.9867 - val_loss: 0.1120\n",
      "Epoch 63/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9297 - loss: 0.1627\n",
      "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9305 - loss: 0.1634 - val_accuracy: 0.9867 - val_loss: 0.1058\n",
      "Epoch 64/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9219 - loss: 0.1458\n",
      "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9275 - loss: 0.1669 - val_accuracy: 0.9751 - val_loss: 0.0911\n",
      "Epoch 65/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9453 - loss: 0.1675\n",
      "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9349 - loss: 0.1785 - val_accuracy: 0.9552 - val_loss: 0.0901\n",
      "Epoch 66/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9062 - loss: 0.1645\n",
      "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9227 - loss: 0.1697 - val_accuracy: 0.9917 - val_loss: 0.0912\n",
      "Epoch 67/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9297 - loss: 0.1672\n",
      "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9421 - loss: 0.1549 - val_accuracy: 0.9900 - val_loss: 0.1049\n",
      "Epoch 68/1000\n",
      "\u001B[1m 1/11\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9531 - loss: 0.1371\n",
      "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier_glove.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9450 - loss: 0.1675 - val_accuracy: 0.9585 - val_loss: 0.1127\n",
      "Epoch 68: early stopping\n"
     ]
    }
   ],
   "source": [
    "GQ_CLASSES = 2\n",
    "GQmodel = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((172, 1), input_shape=(172,)),\n",
    "    tf.keras.layers.Conv1D(16, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=10),\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(GQ_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "GQmodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1)\n",
    "\n",
    "history = GQmodel.fit(\n",
    "    X_train_GQ,\n",
    "    Y_train_GQ,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_validation_GQ, Y_validation_GQ),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:51:23.524871100Z",
     "start_time": "2024-04-20T15:51:13.500338500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 947us/step - accuracy: 0.6271 - loss: 1.2457\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = GQmodel.evaluate(X_test_GQ, Y_test_GQ, batch_size = 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:51:23.672416200Z",
     "start_time": "2024-04-20T15:51:23.525872100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 700x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       100\n",
      "           1       0.50      0.50      0.50       100\n",
      "\n",
      "    accuracy                           0.50       200\n",
      "   macro avg       0.50      0.50      0.50       200\n",
      "weighted avg       0.50      0.50      0.50       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "\n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "Y_pred_GQ = GQmodel.predict(X_test_GQ)\n",
    "Y_pred_GQ = np.argmax(Y_pred_GQ, axis=1)\n",
    "\n",
    "print_confusion_matrix(Y_test_GQ, Y_pred_GQ)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T16:01:48.891362600Z",
     "start_time": "2024-04-20T16:01:48.720473500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T15:35:21.650705100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
